[
    {
    "input": {
      "starting_page": 37,
      "academic_year": "2025-26",
      "department": "B.E/Dept of CSE/BNMIT",
      "project_title": "Yoga Pose Recommender System",
      "contents_txt":  "CHAPTER   III  -  System Requirement Specification\n\n3.1 Hardware Requirements\n\nThe development of the Yoga Pose Recommender System relies on a carefully selected software stack that enables seamless integration of cloud services, artificial intelligence, and real-time user interaction. The software requirements define the necessary tools, platforms, libraries, and frameworks needed to design, develop, deploy, and maintain the application efficiently. Given the cloud-centric nature of the system, the selection of software focuses heavily on compatibility with Google Cloud services such as Vertex AI, Firestore, and Cloud Run, ensuring that all components work in harmony within a scalable and serverless environment. The use of advanced AI models and real-time pose estimation demands support for machine learning frameworks and lightweight processing libraries that can run efficiently on both cloud infrastructure and client-side devices.\n\nFurthermore, the software requirements are driven by the system’s need to support multimodal input (text and speech), dynamic UI interaction, and webcam-based pose detection. On the frontend, modern JavaScript frameworks and browser APIs such as the Web Speech API are essential for voice-based interaction and rendering real-time video overlays. On the backend, Java and Python are chosen for their robust ecosystem and compatibility with AI and computer vision workloads. Integration of tools such as  MediaPipe  and OpenCV allows the system to analyze skeletal movements from webcam feeds, while cloud-based deployment tools ensure continuous integration and delivery. Together, these software components form the backbone of a responsive, intelligent, and accessible wellness platform.\n\n3.1.1 Technology used:\n\n• Google Cloud Services\n\nThe Yoga Pose Recommender System leverages several Google Cloud services to ensure a scalable, reliable, and efficient backend. Vertex AI is at the core of the AI  driven  engine. By using pre-trained and fine-tuned models like Gemini 2.0, Vertex AI provides the system with the ability to process and interpret user inputs (both text and speech), enabling the recommendation of suitable yoga poses based on the user's specific needs. Firestore, a real-time NoSQL database, stores metadata about various yoga poses, including descriptions, benefits, and contraindications, and allows the system to retrieve this data quickly and  efficiently during the recommendation process. Google Cloud Run is employed for serverless deployment, which enables automatic scaling and low-latency performance without the need for complex infrastructure management. This choice ensures that the system can handle varying user traffic seamlessly, providing high availability while reducing operational costs.\n\n• Python\n\nPython serves as the primary programming language for implementing backend functionalities, particularly the pose detection and analysis components of the system. Using libraries such as  MediaPipe  and OpenCV, Python enables real-time  webcam based  pose estimation by detecting key skeletal landmarks and providing immediate feedback on posture accuracy.  MediaPipe  offers efficient solutions for body pose tracking, while OpenCV helps in processing and overlaying skeletal data on live video feeds. Additionally, Python is used to interface with Google Cloud services, handling API calls for recommendations and data retrieval. Its versatility, ease of integration with machine learning models, and strong ecosystem of libraries make it the ideal choice for this project’s backend.\n\n• HTML/CSS (Frontend)\n\nFor the  frontend , HTML and CSS are employed to create a user-friendly, responsive interface. HTML provides the structure of the web pages, ensuring that users can easily navigate through the application and interact with the system. CSS is used to style the interface, ensuring a clean and visually appealing design. Given the project’s emphasis on accessibility, special attention is paid to designing an intuitive layout that supports various input methods, including voice and text. CSS ensures the layout is adaptable to different screen sizes, improving usability on both desktops and mobile devices. Together, HTML and CSS form the backbone of a frontend that is both functional and easy to navigate for users of all backgrounds.\n\n• JavaScript and Web Speech API\n\nJavaScript is used to add interactivity to the frontend, handling user interactions and managing data flow between the user interface and backend services. The Web Speech API is particularly important for enabling voice-based input and text-to speech functionality. This API allows users to dictate their symptoms or requests (such as “neck pain” or “stress relief”) and receive spoken yoga instructions in return. The integration of the Web Speech API enhances accessibility, allowing the app to support hands-free operation, which is essential for users with disabilities or those who prefer voice interactions over typing.\n\n3.1.2 Tools used:\n\n• Gemini API\n\nThe Gemini API, a large language model from Google’s Vertex AI, is central to the Yoga Pose Recommender System's functionality. Fine-tuned to interpret natural language input, Gemini 2.0  is capable of understanding  a variety of user queries related to pain points, physical conditions, and emotional states. It processes these inputs, such as \"lower back pain\" or \"stress relief,\" and generates intelligent, context-aware recommendations for yoga poses. By leveraging the capabilities of Gemini, the system can accurately match user needs to relevant poses, making the recommendation process more personalized and dynamic. This AI-powered approach enables the system to handle diverse user queries with high accuracy and adaptability, far beyond simple keyword matching.\n\n• Vector Search (Vertex AI)\n\nVertex AI's Vector Search enables efficient semantic search capabilities within the system by indexing pose data as high-dimensional vectors. When a user submits a query, it is transformed into an embedding, and Vertex AI compares this embedding against the indexed pose data. This vector-based search mechanism ensures that the system not only performs traditional keyword-based matching but also understands the underlying intent of the user, providing more accurate and meaningful recommendations.\n\n• Vertex AI (Machine Learning Models)\n\nVertex AI is a comprehensive machine learning platform that provides the infrastructure for building, deploying, and managing AI models at scale. In this system, Vertex AI hosts  fine -tuned models that process user input and deliver pose recommendations based on real-time queries. The integration with Gemini 2.0 allows for highly contextualized responses to user inputs. Vertex AI provides a seamless environment for deploying machine learning models, ensuring that the system scales efficiently with user demand. By using this platform, the Yoga Pose Recommender System benefits from Google's robust infrastructure, enabling it to handle complex machine learning tasks while maintaining high performance and reliability.\n\n• Firestore (Database)\n\nFirestore is a NoSQL cloud database service provided by Google that plays a pivotal role in storing and managing metadata for the yoga poses in the system. Firestore is ideal for this project because of its real-time synchronization capabilities, which ensures that any updates to the pose database are instantly reflected across all user sessions. The metadata stored in Firestore includes detailed information about each yoga pose, such as difficulty, target body areas, step-by-step instructions, benefits, and contraindications. This allows the system  to retrieve relevant pose data quickly and efficiently when generating recommendations, ensuring a smooth and responsive user experience.\n\n•  MediaPipe  and OpenCV (Pose Detection)\n\nMediaPipe  and OpenCV are used for real-time pose detection in the Yoga Pose Recommender System.  MediaPipe  is a cross-platform framework that offers efficient solutions for human body pose estimation, enabling the system to identify key skeletal landmarks on the user's body from webcam input. OpenCV, a popular computer vision library, is used to process and display these landmarks on the video feed, overlaying skeletal markers on the user's live image. This feature provides immediate visual feedback, allowing users to compare their posture with the recommended poses in real time. Together,  MediaPipe  and OpenCV enable accurate and responsive pose tracking, which is a critical aspect of the system's interactive features.\n\n• Web Speech API\n\nThe Web Speech API is integrated into the frontend to support multimodal interaction between the user and the Yoga Pose Recommender System. This API enables speech-to-text functionality, allowing users to interact with the system using voice commands, such as describing pain points (\"I have neck pain\"). In addition, the text-to-speech feature of the Web Speech API is used to convert the system's pose recommendations into spoken instructions, guiding the user through the poses. By incorporating the Web Speech API, the system enhances accessibility for users with visual impairments or those who prefer voice-based interactions over traditional text input.\n\n3.2 Software Requirements\n\n1. Client-Side Device (User’s Computer/Smartphone)\n\n▪ Minimum specifications include a processor (CPU) capable of handling video input (e.g., Intel i3 or equivalent), at least 4 GB of RAM, and a webcam for pose detection. A high-definition (HD) webcam is recommended for optimal accuracy in skeletal tracking.\n\n2. Server-Side Infrastructure (Cloud-Based)\n\n▪ The application is hosted entirely on Google Cloud Platform (GCP), so physical server hardware is abstracted away. However, for scalability and performance, it requires sufficient cloud computing resources such as virtual machine instances on Google Cloud Compute Engine for supporting backend operations, data processing, and API management.\n\n3. Storage Device (Cloud Storage)\n\n▪ The system uses Google Firestore to store pose metadata and  Google Cloud Storage for storing large datasets (e.g., pose images, videos, and machine learning model checkpoints). While physical storage hardware is managed by Google Cloud, ensuring fast read/write speeds and high availability is critical for real-time data access and smooth user experience.\n\n4. Graphics Processing Unit (GPU)\n\n▪ For faster processing of pose detection and real-time video overlay, the system can benefit from using GPU resources, especially when processing multiple concurrent video streams. While basic pose detection can run on CPU, leveraging a NVIDIA GPU (or equivalent) in the cloud can significantly accelerate pose analysis, particularly in machine learning training and inference tasks. This is essential for providing low-latency feedback in real-time pose tracking.\n\n5. Internet Connection\n\n▪ A stable and high-speed internet connection (at least 5 Mbps for smooth video streaming and cloud communication) is required for seamless interaction with the system, particularly for the live webcam feed, voice input, and cloud-based services. Faster connections (10 Mbps or above) will ensure  more  responsive user experience, especially for real-time pose feedback."
    },
    "output": "#page(\n  paper: \"a4\",\n  margin: (top: 1in, bottom: 1in, left: 1.25in, right: 1in),\n  header: none,\n  footer: none,\n  numbering: none\n)[\n  #set text(font: \"Times New Roman\", size: 12pt, fill: black)\n  #set align(center)\n  #v(1fr)\n\n  #text(size: 24pt, weight: \"bold\")[CHAPTER -- III]\n  #v(0.5em)\n  #text(size: 24pt, weight: \"bold\")[SYSTEM REQUIREMENT SPECIFICATION]\n\n  #v(1fr)\n]\n\n#let starting_page = 37\n#counter(page).update(starting_page+1)\n\n#let department = \"B.E/Dept of CSE/BNMIT\"\n#let academic_year = \"2025-26\"\n#let project_title = \"Yoga Pose Recommender System\"\n\n#set page(\n  paper: \"a4\",\n  margin: (top: 1in, bottom: 1in, left: 1.25in, right: 1in),\n  numbering: \"1\",\n  header: context [\n    #if counter(page).get().first() >= starting_page+2 [\n      #set text(size: 12pt, font: \"Times New Roman\", weight: \"bold\")\n      #block(\n        width: 100%,\n        inset: (top: 5pt, bottom: 8pt),\n      )[\n        #stack(\n          dir: ttb,\n          project_title,\n          v(0.3em),\n          spacing: 1.5pt, \n          line(length: 100%, stroke: 0.7pt + rgb(128, 0, 0)),\n          v(0.3em),\n          line(length: 100%, stroke: 3pt + rgb(128, 0, 0))\n        )\n      ]\n    ]\n  ],\n  footer: context [\n    #set text(size: 10pt, font: \"Times New Roman\")\n    #block(\n      width: 100%,\n      inset: (top: 8pt, bottom: 5pt),\n    )[\n      #stack(\n          dir: ttb,\n          spacing: 1.5pt, \n          line(length: 100%, stroke: 3pt + rgb(128, 0, 0)),\n          v(0.3em),\n          line(length: 100%, stroke: 0.7pt + rgb(128, 0, 0))\n        )\n      #grid(\n        columns: (1fr, 1fr, 1fr),\n        align: (left, center, right),\n      )[\n        #department\n      ][\n        Page #counter(page).display()\n      ][\n        #academic_year\n      ]\n    ]\n  ]\n)\n\n#text(size: 16pt, weight: \"bold\")[CHAPTER - III]\n#align(center)[#text(size: 16pt, weight: \"bold\")[SYSTEM REQUIREMENT SPECIFICATION]]\n\n#set par(justify: true, leading: 1.5em, spacing: 2em)\n\n#text(size: 14pt, weight: \"bold\")[3.1 Hardware Requirements]\n\nThe development of the Yoga Pose Recommender System relies on a carefully selected software stack that enables seamless integration of cloud services, artificial intelligence, and real-time user interaction. The software requirements define the necessary tools, platforms, libraries, and frameworks needed to design, develop, deploy, and maintain the application efficiently. Given the cloud-centric nature of the system, the selection of software focuses heavily on compatibility with Google Cloud services such as Vertex AI, Firestore, and Cloud Run, ensuring that all components work in harmony within a scalable and serverless environment. The use of advanced AI models and real-time pose estimation demands support for machine learning frameworks and lightweight processing libraries that can run efficiently on both cloud infrastructure and client-side devices.\n\n#v(1em)\nFurthermore, the software requirements are driven by the system’s need to support multimodal input (text and speech), dynamic UI interaction, and webcam-based pose detection. On the frontend, modern JavaScript frameworks and browser APIs such as the Web Speech API are essential for voice-based interaction and rendering real-time video overlays. On the backend, Java and Python are chosen for their robust ecosystem and compatibility with AI and computer vision workloads. Integration of tools such as  MediaPipe  and OpenCV allows the system to analyze skeletal movements from webcam feeds, while cloud-based deployment tools ensure continuous integration and delivery. Together, these software components form the backbone of a responsive, intelligent, and accessible wellness platform.\n\n#v(1em)\n*3.1.1 Technology used:*\n\n*• Gemini API*\nThe Gemini API, a large language model from Google’s Vertex AI, is central to the Yoga Pose Recommender System's functionality. Fine-tuned to interpret natural language input, Gemini 2.0  is capable of understanding  a variety of user queries related to pain points, physical conditions, and emotional states. It processes these inputs, such as \"lower back pain\" or \"stress relief,\" and generates intelligent, context-aware recommendations for yoga poses. By leveraging the capabilities of Gemini, the system can accurately match user needs to relevant poses, making the recommendation process more personalized and dynamic. This AI-powered approach enables the system to handle diverse user queries with high accuracy and adaptability, far beyond simple keyword matching.\n\n#v(1em)\n*• Vector Search (Vertex AI)*\nVertex AI's Vector Search enables efficient semantic search capabilities within the system by indexing pose data as high-dimensional vectors. When a user submits a query, it is transformed into an embedding, and Vertex AI compares this embedding against the indexed pose data. This vector-based search mechanism ensures that the system not only performs traditional keyword-based matching but also understands the underlying intent of the user, providing more accurate and meaningful recommendations.\n\n#v(1em)\n*• Vertex AI (Machine Learning Models)*\nVertex AI is a comprehensive machine learning platform that provides the infrastructure for building, deploying, and managing AI models at scale. In this system, Vertex AI hosts  fine -tuned models that process user input and deliver pose recommendations based on real-time queries. The integration with Gemini 2.0 allows for highly contextualized responses to user inputs. Vertex AI provides a seamless environment for deploying machine learning models, ensuring that the system scales efficiently with user demand. By using this platform, the Yoga Pose Recommender System benefits from Google's robust infrastructure, enabling it to handle complex machine learning tasks while maintaining high performance and reliability.\n\n#v(1em)\n*• Firestore (Database)*\nFirestore is a NoSQL cloud database service provided by Google that plays a pivotal role in storing and managing metadata for the yoga poses in the system. Firestore is ideal for this project because of its real-time synchronization capabilities, which ensures that any updates to the pose database are instantly reflected across all user sessions. The metadata stored in Firestore includes detailed information about each yoga pose, such as difficulty, target body areas, step-by-step instructions, benefits, and contraindications. This allows the system  to retrieve relevant pose data quickly and efficiently when generating recommendations, ensuring a smooth and responsive user experience.\n\n#v(1em)\n*•  MediaPipe  and OpenCV (Pose Detection)*\nMediaPipe  and OpenCV are used for real-time pose detection in the Yoga Pose Recommender System.  MediaPipe  is a cross-platform framework that offers efficient solutions for human body pose estimation, enabling the system to identify key skeletal landmarks on the user's body from webcam input. OpenCV, a popular computer vision library, is used to process and display these landmarks on the video feed, overlaying skeletal markers on the user's live image. This feature provides immediate visual feedback, allowing users to compare their posture with the recommended poses in real time. Together,  MediaPipe  and OpenCV enable accurate and responsive pose tracking, which is a critical aspect of the system's interactive features.\n\n#v(1em)\n*• Web Speech API*\nThe Web Speech API is integrated into the frontend to support multimodal interaction between the user and the Yoga Pose Recommender System. This API enables speech-to-text functionality, allowing users to interact with the system using voice commands, such as describing pain points (\"I have neck pain\"). In addition, the text-to-speech feature of the Web Speech API is used to convert the system's pose recommendations into spoken instructions, guiding the user through the poses. By incorporating the Web Speech API, the system enhances accessibility for users with visual impairments or those who prefer voice-based interactions over traditional text input.\n\n#v(1em)\n*3.1.2 Tools used:*\n\n*• Google Cloud Services*\nThe Yoga Pose Recommender System leverages several Google Cloud services to ensure a scalable, reliable, and efficient backend. Vertex AI is at the core of the AI  driven  engine. By using pre-trained and fine-tuned models like Gemini 2.0, Vertex AI provides the system with the ability to process and interpret user inputs (both text and speech), enabling the recommendation of suitable yoga poses based on the user's specific needs. Firestore, a real-time NoSQL database, stores metadata about various yoga poses, including descriptions, benefits, and contraindications, and allows the system to retrieve this data quickly and  efficiently during the recommendation process. Google Cloud Run is employed for serverless deployment, which enables automatic scaling and low-latency performance without the need for complex infrastructure management. This choice ensures that the system can handle varying user traffic seamlessly, providing high availability while reducing operational costs.\n\n#v(1em)\n*• Python*\nPython serves as the primary programming language for implementing backend functionalities, particularly the pose detection and analysis components of the system. Using libraries such as  MediaPipe  and OpenCV, Python enables real-time  webcam based  pose estimation by detecting key skeletal landmarks and providing immediate feedback on posture accuracy.  MediaPipe  offers efficient solutions for body pose tracking, while OpenCV helps in processing and overlaying skeletal data on live video feeds. Additionally, Python is used to interface with Google Cloud services, handling API calls for recommendations and data retrieval. Its versatility, ease of integration with machine learning models, and strong ecosystem of libraries make it the ideal choice for this project’s backend.\n\n#v(1em)\n*• HTML/CSS (Frontend)*\nFor the  frontend , HTML and CSS are employed to create a user-friendly, responsive interface. HTML provides the structure of the web pages, ensuring that users can easily navigate through the application and interact with the system. CSS is used to style the interface, ensuring a clean and visually appealing design. Given the project’s emphasis on accessibility, special attention is paid to designing an intuitive layout that supports various input methods, including voice and text. CSS ensures the layout is adaptable to different screen sizes, improving usability on both desktops and mobile devices. Together, HTML and CSS form the backbone of a frontend that is both functional and easy to navigate for users of all backgrounds.\n\n#v(1em)\n*• JavaScript and Web Speech API*\nJavaScript is used to add interactivity to the frontend, handling user interactions and managing data flow between the user interface and backend services. The Web Speech API is particularly important for enabling voice-based input and text-to speech functionality. This API allows users to dictate their symptoms or requests (such as “neck pain” or “stress relief”) and receive spoken yoga instructions in return. The integration of the Web Speech API enhances accessibility, allowing the app to support hands-free operation, which is essential for users with disabilities or those who prefer voice interactions over typing.\n\n#pagebreak()\n#text(size: 14pt, weight: \"bold\")[3.2 Software Requirements]\n\n*1. Client-Side Device (User’s Computer/Smartphone)*\n• Minimum specifications include a processor (CPU) capable of handling video input (e.g., Intel i3 or equivalent), at least 4 GB of RAM, and a webcam for pose detection. A high-definition (HD) webcam is recommended for optimal accuracy in skeletal tracking.\n\n#v(1em)\n*2. Server-Side Infrastructure (Cloud-Based)*\n• The application is hosted entirely on Google Cloud Platform (GCP), so physical server hardware is abstracted away. However, for scalability and performance, it requires sufficient cloud computing resources such as virtual machine instances on Google Cloud Compute Engine for supporting backend operations, data processing, and API management.\n\n#v(1em)\n*3. Storage Device (Cloud Storage)*\n• The system uses Google Firestore to store pose metadata and Google Cloud Storage for storing large datasets (e.g., pose images, videos, and machine learning model checkpoints). While physical storage hardware is managed by Google Cloud, ensuring fast read/write speeds and high availability is critical for real-time data access and smooth user experience.\n\n#v(1em)\n*4. Graphics Processing Unit (GPU)*\n• For faster processing of pose detection and real-time video overlay, the system can benefit from using GPU resources, especially when processing multiple concurrent video streams. While basic pose detection can run on CPU, leveraging a NVIDIA GPU (or equivalent) in the cloud can significantly accelerate pose analysis, particularly in machine learning training and inference tasks. This is essential for providing low-latency feedback in real-time pose tracking.\n\n#v(1em)\n*5. Internet Connection*\n• A stable and high-speed internet connection (at least 5 Mbps for smooth video streaming and cloud communication) is required for seamless interaction with the system, particularly for the live webcam feed, voice input, and cloud-based services. Faster connections (10 Mbps or above) will ensure more responsive user experience, especially for real-time pose feedback."
  },
  {
  "input": {
    "starting_page": 1,
    "academic_year": "2025-26",
    "department": "B.E/Dept of CSE/BNMIT",
    "project_title": "RAG Based PDF Editor",
    "contents_txt": "CHAPTER- I\n\nINTRODUCTION\n\nThis innovative PDF  chatbot  project represents a groundbreaking approach to document interaction, transforming the traditional static reading experience into a dynamic, intelligent conversation system. Built using  Streamlit  as the primary web framework, this application enables users to upload large PDF documents up to 1GB in size and engage in natural language conversations to extract information, generate insights, and create comprehensive analyses directly from document content. The system leverages cutting-edge Retrieval-Augmented Generation (RAG) technology, which combines the power of semantic search capabilities with advanced large language models to provide accurate, contextual responses that extend far beyond simple question-answering scenarios. What truly sets this  chatbot  apart from conventional document processing tools is its sophisticated ability to automatically generate  matplotlib  visualizations, create structured data tables, and produce comprehensive analytical reports based entirely on content extracted from uploaded PDF documents. This makes it an invaluable tool for researchers, business analysts, legal professionals, students, and anyone who needs to quickly extract actionable insights from large document collections while maintaining the flexibility to perform complex analytical tasks without requiring extensive technical knowledge or manual data processing.\n\nThe technical architecture of this system is built upon a robust and scalable foundation that seamlessly integrates multiple state-of-the-art technologies to deliver exceptional performance and user experience. At its core, the application utilizes  PostgreSQL  enhanced with the  pgvector  extension to create a powerful vector database capable of storing and efficiently searching through high-dimensional embeddings generated from document content. The system employs the advanced all-mpnet-base-v2 embedding model from  SentenceTransformers , which produces 768-dimensional vector representations of text chunks, enabling superior semantic understanding and context preservation compared to traditional keyword-based search methods. This sophisticated embedding approach allows the system to understand conceptual relationships between different parts of documents, even when they use different terminology or are expressed in varying writing styles. For natural language processing and response generation, the application integrates  OpenAI's  GPT-4o-mini model, which has been specifically configured to produce structured JSON responses that can include text explanations, executable Python code for visualizations, and data extraction routines for table generation.\n\nThe system's intelligence extends to automatically detecting the type of response required based on user queries, whether they're requesting data visualizations, structured tables, or detailed textual analysis, and then generating appropriate responses in a structured JSON format that enables dynamic content rendering. When users request charts or graphs, the system extracts relevant numerical data from PDF content and  generates complete  matplotlib  code that produces meaningful visualizations, including bar charts for categorical comparisons, line graphs for trend analysis, pie charts for distribution visualization, and scatter plots for correlation analysis. Similarly, when users request tabular data, the system intelligently structures unstructured PDF information into clear, readable pandas  DataFrames  that organize complex information into actionable insights. The document processing capabilities include sophisticated text extraction using  PyPDFLoader , which handles various PDF formats and layouts while preserving document structure and formatting information. The system implements SHA-256 hashing for duplicate detection, ensuring efficient storage and preventing redundant processing of identical documents, while also maintaining detailed metadata about each uploaded file including file sizes, upload timestamps, and processing status.\n\nThe user experience has been carefully designed to provide an intuitive and powerful interface that makes complex document analysis accessible to users regardless of their technical background or expertise level. The main interface features a familiar chat-based design with custom avatar support for brand consistency and professional appearance, while the comprehensive sidebar provides complete document management capabilities including drag-and-drop PDF upload functionality, real-time file size validation with clear feedback mechanisms, document library management with detailed metadata display, and the ability to seamlessly switch between single-document focused searches and multi-document cross-referencing modes. The system supports both focused analysis of individual documents and comprehensive cross-document research, allowing users to identify patterns, contradictions, and complementary information across multiple sources simultaneously. The chat interface maintains conversation history throughout sessions, enabling users to build upon previous queries and maintain context across multiple interactions, while the real-time processing indicators provide clear feedback about system operations including embedding generation progress, search execution status, and response generation phases.\n\nThe practical applications of this PDF  chatbot  span across numerous professional domains and use cases, making it an incredibly versatile tool for modern knowledge work and research activities. In business intelligence scenarios, users can upload financial reports, market research documents, quarterly earnings statements, and industry analyses to quickly extract key performance metrics, generate comprehensive trend analyses, create visual representations of financial data, and produce executive summaries without manually parsing through hundreds of pages of dense documentation. Academic researchers can process multiple research papers simultaneously, compare findings across different studies, extract statistical data for meta-analyses, generate comparative tables that highlight key differences or similarities between various research methodologies and conclusions, and identify gaps in existing literature through cross-document analysis. Legal professionals can leverage the system to analyze contracts, policy documents, regulatory filings, and case law references, quickly finding specific clauses, extracting important dates and obligations, generating summary tables that organize complex legal information into actionable insights, and ensuring comprehensive coverage of relevant legal precedents and requirements."
  },
  "output": "#page(\n  paper: \"a4\",\n  margin: (top: 1in, bottom: 1in, left: 1.25in, right: 1in),\n  header: none,\n  footer: none,\n  numbering: none\n)[\n  #set text(font: \"Times New Roman\", size: 12pt, fill: black)\n  #set align(center)\n  #v(1fr)\n\n  #text(size: 24pt, weight: \"bold\")[CHAPTER -- I]\n  #v(0.5em)\n  #text(size: 24pt, weight: \"bold\")[INTRODUCTION]\n\n  #v(1fr)\n]\n\n#let starting_page = 1\n#counter(page).update(starting_page+1)\n\n#let department = \"B.E/Dept of CSE/BNMIT\"\n#let academic_year = \"2025-26\"\n#let project_title = \"RAG Based PDF Editor\"\n#set page(\n  paper: \"a4\",\n  margin: (top: 1in, bottom: 1in, left: 1.25in, right: 1in),\n  numbering: \"1\",\n  header: context [\n    #if counter(page).get().first() >= starting_page+2 [\n      #set text(size: 12pt, font: \"Times New Roman\", weight: \"bold\")\n      #block(\n        width: 100%,\n        inset: (top: 5pt, bottom: 8pt),\n      )[\n        #stack(\n          dir: ttb,\n          project_title,\n          v(0.3em),\n          spacing: 1.5pt, \n          line(length: 100%, stroke: 0.7pt + rgb(128, 0, 0)),\n          v(0.3em),\n          line(length: 100%, stroke: 3pt + rgb(128, 0, 0))\n        )\n      ]\n    ]\n  ],\n  footer: context [\n    #set text(size: 10pt, font: \"Times New Roman\")\n    #block(\n      width: 100%,\n      inset: (top: 8pt, bottom: 5pt),\n    )[\n      #stack(\n          dir: ttb,\n          spacing: 1.5pt, \n          line(length: 100%, stroke: 3pt + rgb(128, 0, 0)),\n          v(0.3em),\n          line(length: 100%, stroke: 0.7pt + rgb(128, 0, 0))\n        )\n      #grid(\n        columns: (1fr, 1fr, 1fr),\n        align: (left, center, right),\n      )[\n        #department\n      ][\n        Page #counter(page).display()\n      ][\n        #academic_year\n      ]\n    ]\n  ]\n)\n\n#text(size: 16pt, weight: \"bold\")[CHAPTER - I]\n#align(center)[#text(size: 16pt, weight: \"bold\")[INTRODUCTION]]\n\n#set par(justify: true, leading: 1.5em)\n\nThis innovative PDF  chatbot  project represents a groundbreaking approach to document interaction, transforming the traditional static reading experience into a dynamic, intelligent conversation system. Built using  Streamlit  as the primary web framework, this application enables users to upload large PDF documents up to 1GB in size and engage in natural language conversations to extract information, generate insights, and create comprehensive analyses directly from document content. The system leverages cutting-edge Retrieval-Augmented Generation (RAG) technology, which combines the power of semantic search capabilities with advanced large language models to provide accurate, contextual responses that extend far beyond simple question-answering scenarios. What truly sets this  chatbot  apart from conventional document processing tools is its sophisticated ability to automatically generate  matplotlib  visualizations, create structured data tables, and produce comprehensive analytical reports based entirely on content extracted from uploaded PDF documents. This makes it an invaluable tool for researchers, business analysts, legal professionals, students, and anyone who needs to quickly extract actionable insights from large document collections while maintaining the flexibility to perform complex analytical tasks without requiring extensive technical knowledge or manual data processing.\n\n#v(0.5em)\nThe technical architecture of this system is built upon a robust and scalable foundation that seamlessly integrates multiple state-of-the-art technologies to deliver exceptional performance and user experience. At its core, the application utilizes  PostgreSQL  enhanced with the  pgvector  extension to create a powerful vector database capable of storing and efficiently searching through high-dimensional embeddings generated from document content. The system employs the advanced all-mpnet-base-v2 embedding model from  SentenceTransformers , which produces 768-dimensional vector representations of text chunks, enabling superior semantic understanding and context preservation compared to traditional keyword-based search methods. This sophisticated embedding approach allows the system to understand conceptual relationships between different parts of documents, even when they use different terminology or are expressed in varying writing styles. For natural language processing and response generation, the application integrates  OpenAI's  GPT-4o-mini model, which has been specifically configured to produce structured JSON responses that can include text explanations, executable Python code for visualizations, and data extraction routines for table generation.\n\n#v(0.5em)\nThe system's intelligence extends to automatically detecting the type of response required based on user queries, whether they're requesting data visualizations, structured tables, or detailed textual analysis, and then generating appropriate responses in a structured JSON format that enables dynamic content rendering. When users request charts or graphs, the system extracts relevant numerical data from PDF content and  generates complete  matplotlib  code that produces meaningful visualizations, including bar charts for categorical comparisons, line graphs for trend analysis, pie charts for distribution visualization, and scatter plots for correlation analysis. Similarly, when users request tabular data, the system intelligently structures unstructured PDF information into clear, readable pandas  DataFrames  that organize complex information into actionable insights. The document processing capabilities include sophisticated text extraction using  PyPDFLoader , which handles various PDF formats and layouts while preserving document structure and formatting information. The system implements SHA-256 hashing for duplicate detection, ensuring efficient storage and preventing redundant processing of identical documents, while also maintaining detailed metadata about each uploaded file including file sizes, upload timestamps, and processing status.\n\n#v(0.5em)\nThe user experience has been carefully designed to provide an intuitive and powerful interface that makes complex document analysis accessible to users regardless of their technical background or expertise level. The main interface features a familiar chat-based design with custom avatar support for brand consistency and professional appearance, while the comprehensive sidebar provides complete document management capabilities including drag-and-drop PDF upload functionality, real-time file size validation with clear feedback mechanisms, document library management with detailed metadata display, and the ability to seamlessly switch between single-document focused searches and multi-document cross-referencing modes. The system supports both focused analysis of individual documents and comprehensive cross-document research, allowing users to identify patterns, contradictions, and complementary information across multiple sources simultaneously. The chat interface maintains conversation history throughout sessions, enabling users to build upon previous queries and maintain context across multiple interactions, while the real-time processing indicators provide clear feedback about system operations including embedding generation progress, search execution status, and response generation phases.\n\n#v(0.5em)\nThe practical applications of this PDF  chatbot  span across numerous professional domains and use cases, making it an incredibly versatile tool for modern knowledge work and research activities. In business intelligence scenarios, users can upload financial reports, market research documents, quarterly earnings statements, and industry analyses to quickly extract key performance metrics, generate comprehensive trend analyses, create visual representations of financial data, and produce executive summaries without manually parsing through hundreds of pages of dense documentation. Academic researchers can process multiple research papers simultaneously, compare findings across different studies, extract statistical data for meta-analyses, generate comparative tables that highlight key differences or similarities between various research methodologies and conclusions, and identify gaps in existing literature through cross-document analysis. Legal professionals can leverage the system to analyze contracts, policy documents, regulatory filings, and case law references, quickly finding specific clauses, extracting important dates and obligations, generating summary tables that organize complex legal information into actionable insights, and ensuring comprehensive coverage of relevant legal precedents and requirements.\n"
  }
]