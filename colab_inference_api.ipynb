{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fefd93",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.5' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/an1154/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers accelerate peft torch fastapi uvicorn pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606dcfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from fastapi import FastAPI, HTTPException, Depends, Header\n",
    "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "from pyngrok import ngrok\n",
    "import nest_asyncio\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa86e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_MODEL = \"google/t5-small\"\n",
    "ADAPTER_MODEL = \"your_username/t5-small-typst-lora\"\n",
    "HF_TOKEN = \"your_huggingface_token_here\"\n",
    "API_TOKEN = \"your_secure_bearer_token_here\"  # Change this!\n",
    "NGROK_AUTH_TOKEN = \"your_ngrok_auth_token_here\"  # Get from ngrok.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991adc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Hugging Face\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999694ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32\n",
    ")\n",
    "\n",
    "# Load LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_MODEL)\n",
    "model.eval()\n",
    "print(\"‚úÖ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI setup\n",
    "app = FastAPI(title=\"T5 Typst Generator API\")\n",
    "security = HTTPBearer()\n",
    "\n",
    "class GenerateRequest(BaseModel):\n",
    "    input: str\n",
    "\n",
    "class GenerateResponse(BaseModel):\n",
    "    output: str\n",
    "\n",
    "def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):\n",
    "    if credentials.credentials != API_TOKEN:\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid authentication token\")\n",
    "    return credentials.credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/generate\", response_model=GenerateResponse)\n",
    "async def generate(request: GenerateRequest, token: str = Depends(verify_token)):\n",
    "    try:\n",
    "        # Tokenize input\n",
    "        inputs = tokenizer(\n",
    "            request.input,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=4096\n",
    "        ).to(model.device)\n",
    "        \n",
    "        # Generate output with T5 - INCREASED max_length for full documents\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_length=4096,  # Increased from 512 to 2048\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        # Decode output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        return GenerateResponse(output=generated_text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\"status\": \"healthy\", \"model\": ADAPTER_MODEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ngrok\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(8002)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üöÄ Public API Endpoint: {public_url}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nExample usage:\")\n",
    "print(f\"curl -X POST {public_url}/generate \\\\\")\n",
    "print(f'  -H \"Authorization: Bearer {API_TOKEN}\" \\\\')\n",
    "print(f'  -H \"Content-Type: application/json\" \\\\')\n",
    "print(f'  -d \\'{{\"input\": \"your prompt here\"}}\\'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbbc3ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.5' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "# Run FastAPI server\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8002)  # Changed from 8003 to 8000\n",
    "\n",
    "thread = threading.Thread(target=run_server, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "time.sleep(5)\n",
    "print(\"‚úÖ Server started in background thread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b459e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Use the ngrok URL from the output above\n",
    "url = \"https://microbic-leonida-disgustingly.ngrok-free.dev/generate\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer Qwen-model-token\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Helper function to convert dict to string format\n",
    "def format_input_dict(input_dict):\n",
    "    \"\"\"Convert input dictionary to the training format string\"\"\"\n",
    "    return f\"\"\"Convert to IEEE-style Typst markup.\n",
    "Metadata: Starting Page: {input_dict['starting_page']}, Academic Year: {input_dict['academic_year']}, Department: {input_dict['department']}, Project Title: {input_dict['project_title']}\n",
    "Chapter Text: {input_dict['contents_txt']}\"\"\"\n",
    "\n",
    "# Your input data as dictionary\n",
    "input_data = {\n",
    "    \"starting_page\": 8,\n",
    "    \"academic_year\": \"2025-26\",\n",
    "    \"department\": \"B.E/Dept of CSE/BNMIT\",\n",
    "    \"project_title\": \"Sleep Apnea Detection\",\n",
    "    \"contents_txt\": \"\"\"CHAPTER- VI  :  Results and  Discussions\n",
    "\n",
    "#figure(\n",
    "  image(\"image008.jpg\", width: 50%),\n",
    "  caption: [Fig 6. 2  Gender  and  Age Distribution]\n",
    ")\n",
    "\n",
    "Fig 6. 2  shows the number of females and males  and   the distribution of people across different age groups. The x-axis shows age and the y-axis shows the  count.\n",
    "\n",
    "#figure(\n",
    "  image(\"image007.jpg\", width: 50%),\n",
    "  caption: [Fig 6.1 Sleep Duration Distribution  and  Exercise frequency during a  week]\n",
    ")\n",
    "\n",
    "The above count plots Fig 6.1 shows the distribution of sleep duration vs count, the bars on the graph represent the number of people who slept for a certain amount of time.  It also  shows the Exercise frequency vs count, Similar to the sleep duration plot, the bars represent how many people exercised a certain number of times.\n",
    "\n",
    "#figure(\n",
    "  image(\"image009.jpg\", width: 50%),\n",
    "  caption: [Fig 6. 3  Sleep apnea]\n",
    ")\n",
    "\n",
    "From the above plot we can infer that not many people are suffering with sleep apnea. But few people are suffering because of lower REM cycle and more number of awakenings\n",
    "\n",
    "#figure(\n",
    "  image(\"image010.jpg\", width: 50%),\n",
    "  caption: [Fig 6. 4  Count of Sleep Apnea by Gend er]\n",
    ")\n",
    "\n",
    "#figure(\n",
    "  image(\"image011.jpg\", width: 50%),\n",
    "  caption: [Fig 6. 5  Data Analysis]\n",
    ")\n",
    "\n",
    "Fig 6. 5  shows the data set and the GUI representation of the analysis.\n",
    "\n",
    "#figure(\n",
    "  image(\"image012.jpg\", width: 50%),\n",
    "  caption: [Fig  6. 6   Sleep Apnea prediction]\n",
    ")\n",
    "\n",
    "The above Fig 6. 6  shows the sleep apnea prediction data along with the  the  gender based  distribution.From  the distribution, we can infer that many male consuming alcohol are  suffering.In  general many men have sleep apnea  than women.\"\"\"\n",
    "}\n",
    "\n",
    "# Convert dict to string format\n",
    "formatted_input = format_input_dict(input_data)\n",
    "\n",
    "# Send as string\n",
    "payload = {\n",
    "    \"input\": formatted_input\n",
    "}\n",
    "\n",
    "print(\"Sending request to API...\")\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Content-Type: {response.headers.get('Content-Type', 'N/A')}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        result = response.json()\n",
    "        print(\"\\n‚úÖ SUCCESS!\")\n",
    "        print(\"\\nGenerated Typst Output:\")\n",
    "        print(\"=\"*70)\n",
    "        print(result[\"output\"])\n",
    "        print(\"=\"*70)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå JSON parsing error: {e}\")\n",
    "        print(f\"Full response:\\n{response.text}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Error: {response.status_code}\")\n",
    "    print(f\"Response: {response.text[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb05a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
